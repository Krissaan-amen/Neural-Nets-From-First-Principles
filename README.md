# Deep Learning: From Algorithms to Architectures

![Python](https://img.shields.io/badge/Python-3.8%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0%2B-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)

## Overview

This repository houses a suite of deep learning implementations designed to bridge the gap between theoretical mathematics and practical application. It progresses from **low-level algorithmic construction**—implementing backpropagation and gradient descent without frameworks—to deploying **state-of-the-art architectures** like LSTMs and Variational Autoencoders (VAEs) using TensorFlow and Keras.

The project demonstrates proficiency in both **R** and **Python** ecosystems, focusing on model interpretability, manifold learning, and generative AI.

## Technical Implementations

| Domain | Key Architectures | Technical Focus & Objectives |
| :--- | :--- | :--- |
| **Mathematical Foundations** | **Backpropagation (From Scratch)** | -  Raw implementation of Gradient Descent optimization.<br>-  Demonstration of the chain rule and weight updates without auto-diff libraries. |
| **Computer Vision** | **CNNs & Manifold Untangling** | -  Analyzing how deep networks disentangle high-dimensional data in latent space.<br>-  Custom architecture design using Keras Functional API. |
| **Sequence Modeling** | **RNNs & LSTMs** | -  Implementation of Long Short-Term Memory units for temporal dependencies.<br>-  Applied to time-series forecasting and sequence processing. |
| **Generative AI** | **VAEs & Autoencoders** | -  Building Variational Autoencoders for probabilistic generation.<br>-  Non-linear dimensionality reduction and latent space representation. |

## Usage Guide

```bash
# Clone the repository
git clone https://github.com/Krissaan-amen/Neural_Nets_From_First_Principles.git

# Navigate to specific implementation
cd Deep-Learning-Architectures/03_Sequence_Modeling
```

## Future Projects

This repository is actively evolving with planned implementations including:

- **Transformer Architectures**: Self-attention mechanisms and large language model foundations
- **Graph Neural Networks (GNNs)**: Node classification and graph-level prediction tasks
- **Reinforcement Learning**: Deep Q-Networks and policy gradient methods
- **Advanced Generative Models**: Diffusion models and GANs for high-fidelity image synthesis
- **MLOps Integration**: Model deployment pipelines and production monitoring systems

## Contact

For questions, collaborations, or discussions about deep learning implementations:

 **Email**: [amen.krissaan@gmail.com](mailto:amen.krissaan@gmail.com)

---

*Contributions and feedback are welcome. Please feel free to open issues or submit pull requests.*
